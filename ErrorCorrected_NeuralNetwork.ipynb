{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3cBLy9VjVhU9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cBLy9VjVhU9",
        "outputId": "34fa7407-0352-492d-a351-4cfda2f8203f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-0.43.2.tar.gz (9.1 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.6.1-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pylatexenc\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting qiskit-terra==0.24.1 (from qiskit)\n",
            "  Downloading qiskit_terra-0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qiskit-aer==0.12.1 (from qiskit)\n",
            "  Downloading qiskit_aer-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qiskit-ibmq-provider==0.20.2 (from qiskit)\n",
            "  Downloading qiskit_ibmq_provider-0.20.2-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.5/241.5 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer==0.12.1->qiskit) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer==0.12.1->qiskit) (1.10.1)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibmq-provider==0.20.2->qiskit) (2.27.1)\n",
            "Collecting requests-ntlm<=1.1.0 (from qiskit-ibmq-provider==0.20.2->qiskit)\n",
            "  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibmq-provider==0.20.2->qiskit) (1.26.16)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibmq-provider==0.20.2->qiskit) (2.8.2)\n",
            "Requirement already satisfied: websocket-client>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibmq-provider==0.20.2->qiskit) (1.6.0)\n",
            "Collecting websockets>=10.0 (from qiskit-ibmq-provider==0.20.2->qiskit)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rustworkx>=0.12.0 (from qiskit-terra==0.24.1->qiskit)\n",
            "  Downloading rustworkx-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ply>=3.10 (from qiskit-terra==0.24.1->qiskit)\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra==0.24.1->qiskit) (5.9.5)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra==0.24.1->qiskit) (1.11.1)\n",
            "Collecting dill>=0.3 (from qiskit-terra==0.24.1->qiskit)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stevedore>=3.0.0 (from qiskit-terra==0.24.1->qiskit)\n",
            "  Downloading stevedore-5.1.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting symengine<0.10,>=0.9 (from qiskit-terra==0.24.1->qiskit)\n",
            "  Downloading symengine-0.9.2-cp310-cp310-manylinux2010_x86_64.whl (37.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.5/37.5 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.2.2)\n",
            "Collecting fastdtw (from qiskit_machine_learning)\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (67.7.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->qiskit_machine_learning) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->qiskit_machine_learning) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider==0.20.2->qiskit) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.20.2->qiskit) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.20.2->qiskit) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.20.2->qiskit) (3.4)\n",
            "Collecting ntlm-auth>=1.0.2 (from requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2->qiskit)\n",
            "  Downloading ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting cryptography>=1.3 (from requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2->qiskit)\n",
            "  Downloading cryptography-41.0.1-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0 (from stevedore>=3.0.0->qiskit-terra==0.24.1->qiskit)\n",
            "  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit-terra==0.24.1->qiskit) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=1.3->requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2->qiskit) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2->qiskit) (2.21)\n",
            "Building wheels for collected packages: qiskit, pylatexenc, fastdtw\n",
            "  Building wheel for qiskit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit: filename=qiskit-0.43.2-py3-none-any.whl size=7640 sha256=adda922b8bf4bcf95ebd3f58236575baefd81ba8f9f6124dbef8a9c43bdee7c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/ad/4f/f54eb8743e54c5bab69837b842cf56a8a87ac7c57a2abf85ad\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136820 sha256=402b935f9b47f2344e10611dbf55611df4eda59d1c86712344b5d94c160b75dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp310-cp310-linux_x86_64.whl size=517924 sha256=b1803afaa438040181ac47730678de787791ca37d6e5c3acf1ada8cc189ab130\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/c8/f7/c25448dab74c3acf4848bc25d513c736bb93910277e1528ef4\n",
            "Successfully built qiskit pylatexenc fastdtw\n",
            "Installing collected packages: pylatexenc, ply, websockets, symengine, rustworkx, pbr, ntlm-auth, fastdtw, dill, stevedore, cryptography, requests-ntlm, qiskit-terra, qiskit_machine_learning, qiskit-ibmq-provider, qiskit-aer, qiskit\n",
            "Successfully installed cryptography-41.0.1 dill-0.3.6 fastdtw-0.3.4 ntlm-auth-1.5.0 pbr-5.11.1 ply-3.11 pylatexenc-2.10 qiskit-0.43.2 qiskit-aer-0.12.1 qiskit-ibmq-provider-0.20.2 qiskit-terra-0.24.1 qiskit_machine_learning-0.6.1 requests-ntlm-1.1.0 rustworkx-0.13.0 stevedore-5.1.0 symengine-0.9.2 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "#IMPORTANT: after running this block you need to restart the runtime\n",
        "#to do this go to Runtime at the top and click Restart runtime\n",
        "%pip install qiskit qiskit_machine_learning pylatexenc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intense-ecology",
      "metadata": {
        "id": "intense-ecology"
      },
      "source": [
        "# Neural Network Classifier & Regressor\n",
        "\n",
        "In this tutorial we show how the `NeuralNetworkClassifier` and `NeuralNetworkRegressor` are used.\n",
        "Both take as an input a (Quantum) `NeuralNetwork` and leverage it in a specific context.\n",
        "In both cases we also provide a pre-configured variant for convenience, the Variational Quantum Classifier (`VQC`) and Variational Quantum Regressor (`VQR`). The tutorial is structured as follows:\n",
        "\n",
        "\n",
        "1. [Classification](#Classification)\n",
        "    * Classification with an `EstimatorQNN`\n",
        "    * Classification with a `SamplerQNN`\n",
        "    * Variational Quantum Classifier (`VQC`)\n",
        "    \n",
        "    \n",
        "2. [Regression](#Regression)\n",
        "    * Regression with an `EstimatorQNN`\n",
        "    * Variational Quantum Regressor (`VQR`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "functioning-sword",
      "metadata": {
        "id": "functioning-sword"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.algorithms.optimizers import COBYLA, L_BFGS_B\n",
        "from qiskit.circuit import Parameter\n",
        "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
        "from qiskit.utils import algorithm_globals\n",
        "\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
        "from qiskit_machine_learning.algorithms.regressors import NeuralNetworkRegressor, VQR\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
        "\n",
        "algorithm_globals.random_seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "compact-divide",
      "metadata": {
        "id": "compact-divide"
      },
      "source": [
        "## Classification\n",
        "\n",
        "We prepare a simple classification dataset to illustrate the following algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "short-pierre",
      "metadata": {
        "id": "short-pierre",
        "tags": [
          "nbsphinx-thumbnail"
        ]
      },
      "outputs": [],
      "source": [
        "num_inputs = 2\n",
        "num_samples = 20\n",
        "X = 2 * algorithm_globals.random.random([num_samples, num_inputs]) - 1\n",
        "y01 = 1 * (np.sum(X, axis=1) >= 0)  # in { 0,  1}\n",
        "y = 2 * y01 - 1  # in {-1, +1}\n",
        "y_one_hot = np.zeros((num_samples, 2))\n",
        "for i in range(num_samples):\n",
        "    y_one_hot[i, y01[i]] = 1\n",
        "\n",
        "for x, y_target in zip(X, y):\n",
        "    if y_target == 1:\n",
        "        plt.plot(x[0], x[1], \"bo\")\n",
        "    else:\n",
        "        plt.plot(x[0], x[1], \"go\")\n",
        "plt.plot([-1, 1], [1, -1], \"--\", color=\"black\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "religious-history",
      "metadata": {
        "id": "religious-history"
      },
      "source": [
        "### Classification with an `EstimatorQNN`\n",
        "\n",
        "First we show how an `EstimatorQNN` can be used for classification within a `NeuralNetworkClassifier`. In this context, the `EstimatorQNN` is expected to return one-dimensional output in $[-1, +1]$. This only works for binary classification and we assign the two classes to $\\{-1, +1\\}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "recognized-musician",
      "metadata": {
        "id": "recognized-musician"
      },
      "outputs": [],
      "source": [
        "# construct QNN\n",
        "qc = QuantumCircuit(2)\n",
        "feature_map = ZZFeatureMap(2)\n",
        "ansatz = RealAmplitudes(2)\n",
        "qc.compose(feature_map, inplace=True)\n",
        "qc.compose(ansatz, inplace=True)\n",
        "qc.draw(output=\"mpl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "formed-animal",
      "metadata": {
        "id": "formed-animal"
      },
      "source": [
        "Create a quantum neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "determined-hands",
      "metadata": {
        "id": "determined-hands"
      },
      "outputs": [],
      "source": [
        "estimator_qnn = EstimatorQNN(\n",
        "    circuit=qc, input_params=feature_map.parameters, weight_params=ansatz.parameters\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acute-casting",
      "metadata": {
        "id": "acute-casting"
      },
      "outputs": [],
      "source": [
        "# QNN maps inputs to [-1, +1]\n",
        "estimator_qnn.forward(X[0, :], algorithm_globals.random.random(estimator_qnn.num_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stone-holiday",
      "metadata": {
        "id": "stone-holiday"
      },
      "source": [
        "We will add a callback function called `callback_graph`. This will be called for each iteration of the optimizer and will be passed two parameters: the current weights and the value of the objective function at those weights. For our function, we append the value of the objective function to an array so we can plot iteration versus objective function value and update the graph with each iteration. However, you can do whatever you want with a callback function as long as it gets the two parameters mentioned passed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "similar-controversy",
      "metadata": {
        "id": "similar-controversy"
      },
      "outputs": [],
      "source": [
        "# callback function that draws a live plot when the .fit() method is called\n",
        "def callback_graph(weights, obj_func_eval):\n",
        "    clear_output(wait=True)\n",
        "    objective_func_vals.append(obj_func_eval)\n",
        "    plt.title(\"Objective function value against iteration\")\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Objective function value\")\n",
        "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lesser-receiver",
      "metadata": {
        "id": "lesser-receiver"
      },
      "outputs": [],
      "source": [
        "# construct neural network classifier\n",
        "estimator_classifier = NeuralNetworkClassifier(\n",
        "    estimator_qnn, optimizer=COBYLA(maxiter=60), callback=callback_graph\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adopted-editor",
      "metadata": {
        "id": "adopted-editor"
      },
      "outputs": [],
      "source": [
        "# create empty array for callback to store evaluations of the objective function\n",
        "objective_func_vals = []\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# fit classifier to data\n",
        "estimator_classifier.fit(X, y)\n",
        "\n",
        "# return to default figsize\n",
        "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
        "\n",
        "# score classifier\n",
        "estimator_classifier.score(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "civilian-analysis",
      "metadata": {
        "id": "civilian-analysis"
      },
      "outputs": [],
      "source": [
        "# evaluate data points\n",
        "y_predict = estimator_classifier.predict(X)\n",
        "\n",
        "# plot results\n",
        "# red == wrongly classified\n",
        "for x, y_target, y_p in zip(X, y, y_predict):\n",
        "    if y_target == 1:\n",
        "        plt.plot(x[0], x[1], \"bo\")\n",
        "    else:\n",
        "        plt.plot(x[0], x[1], \"go\")\n",
        "    if y_target != y_p:\n",
        "        plt.scatter(x[0], x[1], s=200, facecolors=\"none\", edgecolors=\"r\", linewidths=2)\n",
        "plt.plot([-1, 1], [1, -1], \"--\", color=\"black\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "japanese-seattle",
      "metadata": {
        "id": "japanese-seattle"
      },
      "source": [
        "Now, when the model is trained, we can explore the weights of the neural network. Please note, the number of weights is defined by ansatz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "offshore-basket",
      "metadata": {
        "id": "offshore-basket"
      },
      "outputs": [],
      "source": [
        "estimator_classifier.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "determined-standing",
      "metadata": {
        "id": "determined-standing"
      },
      "source": [
        "### Classification with a `SamplerQNN`\n",
        "\n",
        "Next we show how a `SamplerQNN` can be used for classification within a `NeuralNetworkClassifier`. In this context, the `SamplerQNN` is expected to return $d$-dimensional probability vector as output, where $d$ denotes the number of classes.\n",
        "The underlying `Sampler` primitive returns quasi-distributions of bit strings and we just need to define a mapping from the measured bitstrings to the different classes. For binary classification we use the parity mapping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "discrete-factor",
      "metadata": {
        "id": "discrete-factor"
      },
      "outputs": [],
      "source": [
        "# construct feature map\n",
        "feature_map = ZZFeatureMap(num_inputs)\n",
        "\n",
        "# construct ansatz\n",
        "ansatz = RealAmplitudes(num_inputs, reps=1)\n",
        "\n",
        "# construct quantum circuit\n",
        "qc = QuantumCircuit(num_inputs)\n",
        "qc.append(feature_map, range(num_inputs))\n",
        "qc.append(ansatz, range(num_inputs))\n",
        "qc.decompose().draw(output=\"mpl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "young-sensitivity",
      "metadata": {
        "id": "young-sensitivity"
      },
      "outputs": [],
      "source": [
        "# parity maps bitstrings to 0 or 1\n",
        "def parity(x):\n",
        "    return \"{:b}\".format(x).count(\"1\") % 2\n",
        "\n",
        "\n",
        "output_shape = 2  # corresponds to the number of classes, possible outcomes of the (parity) mapping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statutory-mercury",
      "metadata": {
        "id": "statutory-mercury"
      },
      "outputs": [],
      "source": [
        "# construct QNN\n",
        "sampler_qnn = SamplerQNN(\n",
        "    circuit=qc,\n",
        "    input_params=feature_map.parameters,\n",
        "    weight_params=ansatz.parameters,\n",
        "    interpret=parity,\n",
        "    output_shape=output_shape,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hybrid-orlando",
      "metadata": {
        "id": "hybrid-orlando"
      },
      "outputs": [],
      "source": [
        "# construct classifier\n",
        "sampler_classifier = NeuralNetworkClassifier(\n",
        "    neural_network=sampler_qnn, optimizer=COBYLA(maxiter=30), callback=callback_graph\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adult-newman",
      "metadata": {
        "id": "adult-newman"
      },
      "outputs": [],
      "source": [
        "# create empty array for callback to store evaluations of the objective function\n",
        "objective_func_vals = []\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# fit classifier to data\n",
        "sampler_classifier.fit(X, y01)\n",
        "\n",
        "# return to default figsize\n",
        "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
        "\n",
        "# score classifier\n",
        "sampler_classifier.score(X, y01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "angry-bulgarian",
      "metadata": {
        "id": "angry-bulgarian"
      },
      "outputs": [],
      "source": [
        "# evaluate data points\n",
        "y_predict = sampler_classifier.predict(X)\n",
        "\n",
        "# plot results\n",
        "# red == wrongly classified\n",
        "for x, y_target, y_p in zip(X, y01, y_predict):\n",
        "    if y_target == 1:\n",
        "        plt.plot(x[0], x[1], \"bo\")\n",
        "    else:\n",
        "        plt.plot(x[0], x[1], \"go\")\n",
        "    if y_target != y_p:\n",
        "        plt.scatter(x[0], x[1], s=200, facecolors=\"none\", edgecolors=\"r\", linewidths=2)\n",
        "plt.plot([-1, 1], [1, -1], \"--\", color=\"black\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "assisted-individual",
      "metadata": {
        "id": "assisted-individual"
      },
      "source": [
        "Again, once the model is trained we can take a look at the weights. As we set `reps=1` explicitly in our ansatz, we can see less parameters than in the previous model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "indonesian-bulletin",
      "metadata": {
        "id": "indonesian-bulletin"
      },
      "outputs": [],
      "source": [
        "sampler_classifier.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "champion-approval",
      "metadata": {
        "id": "champion-approval"
      },
      "source": [
        "### Variational Quantum Classifier (`VQC`)\n",
        "\n",
        "The `VQC` is a special variant of the `NeuralNetworkClassifier` with a `SamplerQNN`. It applies a parity mapping (or extensions to multiple classes) to map from the bitstring to the classification, which results in a probability vector, which is interpreted as a one-hot encoded result. By default, it applies this the `CrossEntropyLoss` function that expects labels given in one-hot encoded format and will return predictions in that format too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "legislative-dublin",
      "metadata": {
        "id": "legislative-dublin"
      },
      "outputs": [],
      "source": [
        "# construct feature map, ansatz, and optimizer\n",
        "feature_map = ZZFeatureMap(num_inputs)\n",
        "ansatz = RealAmplitudes(num_inputs, reps=1)\n",
        "\n",
        "# construct variational quantum classifier\n",
        "vqc = VQC(\n",
        "    feature_map=feature_map,\n",
        "    ansatz=ansatz,\n",
        "    loss=\"cross_entropy\",\n",
        "    optimizer=COBYLA(maxiter=30),\n",
        "    callback=callback_graph,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "geographic-adjustment",
      "metadata": {
        "id": "geographic-adjustment"
      },
      "outputs": [],
      "source": [
        "# create empty array for callback to store evaluations of the objective function\n",
        "objective_func_vals = []\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# fit classifier to data\n",
        "vqc.fit(X, y_one_hot)\n",
        "\n",
        "# return to default figsize\n",
        "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
        "\n",
        "# score classifier\n",
        "vqc.score(X, y_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stopped-heavy",
      "metadata": {
        "id": "stopped-heavy"
      },
      "outputs": [],
      "source": [
        "# evaluate data points\n",
        "y_predict = vqc.predict(X)\n",
        "\n",
        "# plot results\n",
        "# red == wrongly classified\n",
        "for x, y_target, y_p in zip(X, y_one_hot, y_predict):\n",
        "    if y_target[0] == 1:\n",
        "        plt.plot(x[0], x[1], \"bo\")\n",
        "    else:\n",
        "        plt.plot(x[0], x[1], \"go\")\n",
        "    if not np.all(y_target == y_p):\n",
        "        plt.scatter(x[0], x[1], s=200, facecolors=\"none\", edgecolors=\"r\", linewidths=2)\n",
        "plt.plot([-1, 1], [1, -1], \"--\", color=\"black\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "grave-testament",
      "metadata": {
        "id": "grave-testament"
      },
      "source": [
        "### Multiple classes with VQC\n",
        "In this section we generate an artificial dataset that contains samples of three classes and show how to train a model to classify this dataset. This example shows how to tackle more interesting problems in machine learning. Of course, for a sake of short training time we prepare a tiny dataset. We employ `make_classification` from SciKit-Learn to generate a dataset. There 10 samples in the dataset, 2 features, that means we can still have a nice plot of the dataset, as well as no redundant features, these are features are generated as a combinations of the other features. Also, we have 3 different classes in the dataset, each classes one kind of centroid and we set class separation to `2.0`, a slight increase from the default value of `1.0` to ease the classification problem.\n",
        "\n",
        "Once the dataset is generated we scale the features into the range `[0, 1]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plastic-dividend",
      "metadata": {
        "id": "plastic-dividend"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=10,\n",
        "    n_features=2,\n",
        "    n_classes=3,\n",
        "    n_redundant=0,\n",
        "    n_clusters_per_class=1,\n",
        "    class_sep=2.0,\n",
        "    random_state=algorithm_globals.random_seed,\n",
        ")\n",
        "X = MinMaxScaler().fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "forced-disclosure",
      "metadata": {
        "id": "forced-disclosure"
      },
      "source": [
        "Let's see how our dataset looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "premier-drill",
      "metadata": {
        "id": "premier-drill"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deadly-response",
      "metadata": {
        "id": "deadly-response"
      },
      "source": [
        "We also transform labels and make them categorical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exposed-bailey",
      "metadata": {
        "id": "exposed-bailey"
      },
      "outputs": [],
      "source": [
        "y_cat = np.empty(y.shape, dtype=str)\n",
        "y_cat[y == 0] = \"A\"\n",
        "y_cat[y == 1] = \"B\"\n",
        "y_cat[y == 2] = \"C\"\n",
        "print(y_cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "instructional-headquarters",
      "metadata": {
        "id": "instructional-headquarters"
      },
      "source": [
        "We create an instance of `VQC` similar to the previous example, but in this case we pass a minimal set of parameters. Instead of feature map and ansatz we pass just the number of qubits that is equal to the number of features in the dataset, an optimizer with a low number of iteration to reduce training time, a quantum instance, and a callback to observe progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "latin-result",
      "metadata": {
        "id": "latin-result"
      },
      "outputs": [],
      "source": [
        "vqc = VQC(\n",
        "    num_qubits=2,\n",
        "    optimizer=COBYLA(maxiter=30),\n",
        "    callback=callback_graph,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "proper-bookmark",
      "metadata": {
        "id": "proper-bookmark"
      },
      "source": [
        "Start the training process in the same way as in previous examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reported-pioneer",
      "metadata": {
        "id": "reported-pioneer"
      },
      "outputs": [],
      "source": [
        "# create empty array for callback to store evaluations of the objective function\n",
        "objective_func_vals = []\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# fit classifier to data\n",
        "vqc.fit(X, y_cat)\n",
        "\n",
        "# return to default figsize\n",
        "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
        "\n",
        "# score classifier\n",
        "vqc.score(X, y_cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "weighted-renaissance",
      "metadata": {
        "id": "weighted-renaissance"
      },
      "source": [
        "Despite we had the low number of iterations, we achieved quite a good score. Let see the output of the `predict` method and compare the output with the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "employed-patient",
      "metadata": {
        "id": "employed-patient"
      },
      "outputs": [],
      "source": [
        "predict = vqc.predict(X)\n",
        "print(f\"Predicted labels: {predict}\")\n",
        "print(f\"Ground truth:     {y_cat}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "guided-secret",
      "metadata": {
        "id": "guided-secret"
      },
      "source": [
        "## Regression\n",
        "\n",
        "We prepare a simple regression dataset to illustrate the following algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iraqi-flavor",
      "metadata": {
        "id": "iraqi-flavor"
      },
      "outputs": [],
      "source": [
        "num_samples = 20\n",
        "eps = 0.2\n",
        "lb, ub = -np.pi, np.pi\n",
        "X_ = np.linspace(lb, ub, num=50).reshape(50, 1)\n",
        "f = lambda x: np.sin(x)\n",
        "\n",
        "X = (ub - lb) * algorithm_globals.random.random([num_samples, 1]) + lb\n",
        "y = f(X[:, 0]) + eps * (2 * algorithm_globals.random.random(num_samples) - 1)\n",
        "\n",
        "plt.plot(X_, f(X_), \"r--\")\n",
        "plt.plot(X, y, \"bo\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "talented-capitol",
      "metadata": {
        "id": "talented-capitol"
      },
      "source": [
        "### Regression with an `EstimatorQNN`\n",
        "\n",
        "Here we restrict to regression with an `EstimatorQNN` that returns values in $[-1, +1]$. More complex and also multi-dimensional models could be constructed, also based on `SamplerQNN` but that exceeds the scope of this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "perfect-kelly",
      "metadata": {
        "id": "perfect-kelly"
      },
      "outputs": [],
      "source": [
        "# construct simple feature map\n",
        "param_x = Parameter(\"x\")\n",
        "feature_map = QuantumCircuit(1, name=\"fm\")\n",
        "feature_map.ry(param_x, 0)\n",
        "\n",
        "# construct simple ansatz\n",
        "param_y = Parameter(\"y\")\n",
        "ansatz = QuantumCircuit(1, name=\"vf\")\n",
        "ansatz.ry(param_y, 0)\n",
        "\n",
        "# construct a circuit\n",
        "qc = QuantumCircuit(1)\n",
        "qc.compose(feature_map, inplace=True)\n",
        "qc.compose(ansatz, inplace=True)\n",
        "\n",
        "# construct QNN\n",
        "regression_estimator_qnn = EstimatorQNN(\n",
        "    circuit=qc, input_params=feature_map.parameters, weight_params=ansatz.parameters\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "velvet-marks",
      "metadata": {
        "id": "velvet-marks"
      },
      "outputs": [],
      "source": [
        "# construct the regressor from the neural network\n",
        "regressor = NeuralNetworkRegressor(\n",
        "    neural_network=regression_estimator_qnn,\n",
        "    loss=\"squared_error\",\n",
        "    optimizer=L_BFGS_B(maxiter=5),\n",
        "    callback=callback_graph,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "working-mongolia",
      "metadata": {
        "id": "working-mongolia"
      },
      "outputs": [],
      "source": [
        "# create empty array for callback to store evaluations of the objective function\n",
        "objective_func_vals = []\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# fit to data\n",
        "regressor.fit(X, y)\n",
        "\n",
        "# return to default figsize\n",
        "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
        "\n",
        "# score the result\n",
        "regressor.score(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "diverse-conservative",
      "metadata": {
        "id": "diverse-conservative"
      },
      "outputs": [],
      "source": [
        "# plot target function\n",
        "plt.plot(X_, f(X_), \"r--\")\n",
        "\n",
        "# plot data\n",
        "plt.plot(X, y, \"bo\")\n",
        "\n",
        "# plot fitted line\n",
        "y_ = regressor.predict(X_)\n",
        "plt.plot(X_, y_, \"g-\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "false-india",
      "metadata": {
        "id": "false-india"
      },
      "source": [
        "Similarly to the classification models, we can obtain an array of trained weights by querying a corresponding property of the model. In this model we have only one parameter defined as `param_y` above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "terminal-turner",
      "metadata": {
        "id": "terminal-turner"
      },
      "outputs": [],
      "source": [
        "regressor.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "offensive-legislation",
      "metadata": {
        "id": "offensive-legislation"
      },
      "source": [
        "### Regression with the Variational Quantum Regressor (`VQR`)\n",
        "\n",
        "Similar to the `VQC` for classification, the `VQR` is a special variant of the `NeuralNetworkRegressor` with a `EstimatorQNN`. By default it considers the `L2Loss` function to minimize the mean squared error between predictions and targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "offensive-entry",
      "metadata": {
        "id": "offensive-entry"
      },
      "outputs": [],
      "source": [
        "vqr = VQR(\n",
        "    feature_map=feature_map,\n",
        "    ansatz=ansatz,\n",
        "    optimizer=L_BFGS_B(maxiter=5),\n",
        "    callback=callback_graph,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cooperative-helmet",
      "metadata": {
        "id": "cooperative-helmet"
      },
      "outputs": [],
      "source": [
        "# create empty array for callback to store evaluations of the objective function\n",
        "objective_func_vals = []\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# fit regressor\n",
        "vqr.fit(X, y)\n",
        "\n",
        "# return to default figsize\n",
        "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
        "\n",
        "# score result\n",
        "vqr.score(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "genetic-cambridge",
      "metadata": {
        "id": "genetic-cambridge"
      },
      "outputs": [],
      "source": [
        "# plot target function\n",
        "plt.plot(X_, f(X_), \"r--\")\n",
        "\n",
        "# plot data\n",
        "plt.plot(X, y, \"bo\")\n",
        "\n",
        "# plot fitted line\n",
        "y_ = vqr.predict(X_)\n",
        "plt.plot(X_, y_, \"g-\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "backed-visit",
      "metadata": {
        "id": "backed-visit"
      },
      "outputs": [],
      "source": [
        "import qiskit.tools.jupyter\n",
        "\n",
        "%qiskit_version_table\n",
        "%qiskit_copyright"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
